# âš¡ LEGOLAS - Quick Reference

## ðŸš€ Comandi Essenziali

### Training + Evaluation
```bash
./scripts/launch_run_train_eval
```
Menu interattivo con:
- 3 formati storie (narrativo, bullet, clinical)
- 13 modelli biomedici
- 3 modalitÃ  (training, eval, completo)

**Output**:
- Modello: `output/models/xes_{formato}_{modello}*.pth`
- Log eval: `output/evaluation/eval_{formato}_{modello}_{timestamp}.log`
- Predizioni: `prediction/xes_{formato}_{modello}_*.pkl`
- Report: `prediction/xes_{formato}_{modello}_report.txt`

---

## ðŸ“Š Modelli Disponibili

### Biomedici Specializzati (consigliati)
```
clinical-bert          â†’ Note cliniche (default)
pubmedbert-base        â†’ Letteratura PubMed
biobert-base           â†’ Testi biomedici
bluebert-base          â†’ Dominio clinico
clinical-modernbert    â†’ Architettura moderna
scibert-base           â†’ Letteratura scientifica
```

### Longformer (sequenze lunghe)
```
clinical-longformer    â†’ Clinical 4096 token
longformer-base        â†’ Base 4096 token
```

### Generici
```
bert-base-uncased      â†’ BERT standard
bert-large-uncased     â†’ BERT large
bert-italian           â†’ BERT italiano
```

---

## ðŸ“ Struttura Output

```
output/
â”œâ”€â”€ stories/              # Storie generate da XES
â”‚   â”œâ”€â”€ narrativo_*.pkl
â”‚   â”œâ”€â”€ bullet_*.pkl
â”‚   â””â”€â”€ clinical_*.pkl
â”‚
â”œâ”€â”€ models/              # Modelli addestrati
â”‚   â””â”€â”€ xes_narrativo_clinical-bert1.pth
â”‚
â””â”€â”€ evaluation/          # â­ Log evaluation
    â””â”€â”€ eval_narrativo_clinical-bert_20251006_143022.log

prediction/              # Risultati evaluation
â”œâ”€â”€ xes_narrativo_clinical-bert_prob.pkl
â”œâ”€â”€ xes_narrativo_clinical-bert_all_target.pkl
â”œâ”€â”€ xes_narrativo_clinical-bert_all_prediction.pkl
â””â”€â”€ xes_narrativo_clinical-bert_report.txt
```

---

## ðŸ”§ Configurazione

### Aggiungere Nuovo Modello
```yaml
# Edit: config/model_configs.yaml

models:
  my-new-model:
    name: organization/model-id-on-huggingface
    type: bert
    max_length: 512
    num_labels: 8
    description: "Descrizione modello"
    recommended_batch_size: 12
    recommended_lr: 2.0e-5
```

Poi lancia `./scripts/launch_run_train_eval` â†’ appare nel menu automaticamente!

### Modificare Path
```python
# Edit: src/config/paths.py

# Esempio: spostare modelli
MODELS_DIR = PROJECT_ROOT / "models" / "trained"
```

Tutte le modifiche si propagano automaticamente.

---

## ðŸ“ˆ Analisi Risultati

### Ultimo log evaluation
```bash
ls -t output/evaluation/*.log | head -1 | xargs cat
```

### Cerca accuracy
```bash
grep "accuracy" output/evaluation/*.log
```

### Confronta F1-score
```bash
grep "f1-score" output/evaluation/*.log | grep "weighted avg"
```

### Lista log per modello
```bash
ls output/evaluation/*clinical-bert*.log
```

---

## ðŸ› Troubleshooting

### "File di storie non trovati"
```bash
./scripts/run_xes_pipeline.sh  # Genera storie prima
```

### "Modello non trovato"
Verifica che esista in:
```bash
cat config/model_configs.yaml | grep -A 5 "model-name"
```

### "Out of memory GPU"
Riduci batch size in `src/training/train_llm.py`:
```python
BATCH = 16  # o 8 per GPU piccole
```

### Lista modelli disponibili
```bash
./scripts/list_models.py menu
```

---

## ðŸ“š Documentazione Completa

```
docs/
â”œâ”€â”€ INTEGRATION_COMPLETE_SUMMARY.md    # â­ Overview completo
â”œâ”€â”€ MODEL_CONFIG_GUIDE.md              # Guida modelli
â”œâ”€â”€ PATH_CENTRALIZATION_COMPLETE.md    # Guida path
â”œâ”€â”€ EVALUATION_LOGGING.md              # Guida logging
â””â”€â”€ BUGFIX_MODEL_CONFIG.md             # Bugfix details
```

---

## ðŸ’¡ Tips & Tricks

### Performance
- **clinical-bert**: Best trade-off accuratezza/velocitÃ 
- **pubmedbert-base**: Ottimo per terminologia medica
- **longformer**: Per note cliniche molto lunghe (>512 token)

### Formati Storie
- **narrativo**: Raccomandato per BERT (piÃ¹ context)
- **bullet**: PiÃ¹ compatto, veloce training
- **clinical**: Sperimentale con token speciali

### GPU Memory
- BERT base: batch 12-16 (OK con 12GB VRAM)
- BERT large: batch 8 (richiede 16GB+)
- Longformer: batch 4-6 (memoria intensivo)

---

## ðŸŽ¯ Workflow Tipico

1. **Genera storie** (se non fatto):
   ```bash
   ./scripts/run_xes_pipeline.sh
   ```

2. **Training + Evaluation**:
   ```bash
   ./scripts/launch_run_train_eval
   ```
   - Formato: narrativo (default)
   - Modello: clinical-bert (consigliato)
   - Azione: 3 (completo)

3. **Analizza risultati**:
   ```bash
   # Log evaluation
   cat output/evaluation/eval_narrativo_clinical-bert_*.log
   
   # Report testuale
   cat prediction/xes_narrativo_clinical-bert_report.txt
   ```

4. **Prova altri modelli**:
   - Ripeti step 2 con modello diverso
   - Confronta log in `output/evaluation/`

---

## ðŸ”— Quick Links

- **Main script**: `scripts/launch_run_train_eval`
- **Model config**: `config/model_configs.yaml`
- **Path config**: `src/config/paths.py`
- **Training code**: `src/training/train_llm.py`
- **Eval code**: `src/training/eval_model.py`

---

## âš¡ One-Liners

```bash
# Lista modelli
./scripts/list_models.py menu

# Test paths
uv run python src/config/paths.py

# Import test
uv run python -c "from src.training.train_llm import *; print('OK')"

# Ultimi 3 log
ls -t output/evaluation/*.log | head -3

# Accuracy tutti i modelli
grep "accuracy" output/evaluation/*.log
```

---

**Need help?** Controlla `docs/INTEGRATION_COMPLETE_SUMMARY.md` per dettagli completi.

âœ… **System ready!** Esegui `./scripts/launch_run_train_eval` per iniziare.
