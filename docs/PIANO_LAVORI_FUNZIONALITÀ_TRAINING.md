ğŸ“‹ Piano Lavori - Training Avanzato

## ğŸ“Š STATO AVANZAMENTO
- **Ultimo aggiornamento**: 8 Ottobre 2025
- **Branch**: `advanced-training`
- **Fase corrente**: FASE 4 - Task 4.3 pronto per approvazione

---

## âœ… FASE 1: Setup Configurazione e Utilities [COMPLETATA]
**Obiettivo**: Creare infrastruttura base

### Task Completati:
- âœ… **1.1**: Creato `src/training/config.py` con classe `TrainingConfig`
  - Dataclass con tutti i parametri di training
  - K-Fold CV: `use_kfold`, `n_folds=10`, stratificato
  - Focal Loss: `focal_alpha=[0.25, 0.75]`, `focal_gamma=2.0`
  - Early Stopping: patience=5, delta+ratio monitoring
  - Best model tracking: balanced_accuracy
  - Path management integrato con struttura LEGOLAS
  - Factory functions: `create_default_config()`, `create_kfold_config()`
  - Validazione configurazione con `validate()`
  - File: **~350 righe**

- âœ… **1.2**: Creato `src/training/focal_loss.py` con implementazione Focal Loss
  - Classe `FocalLoss(nn.Module)` completa
  - Formula: `FL(p_t) = -Î±_t * (1 - p_t)^Î³ * log(p_t)`
  - Supporto alpha (class weights) e gamma (focusing parameter)
  - Reduction modes: mean, sum, none
  - Factory function: `create_focal_loss()`
  - Integration helper: `create_loss_from_config()`
  - Test comparativi Focal vs CrossEntropy
  - File: **~360 righe**

- âœ… **1.3**: Creato `src/training/utils.py` con funzioni utility
  - `stratified_train_val_test_split()`: Split stratificato train/val/test
  - `create_stratified_kfold()`: StratifiedKFold per CV
  - `compute_class_weights()`: Calcolo pesi per classi sbilanciate
  - `compute_metrics()`: Accuracy, balanced_accuracy, precision, recall, F1
  - `compute_detailed_metrics()`: Metriche + confusion matrix + report
  - `save_metrics()` / `load_metrics()`: I/O metriche JSON
  - `analyze_class_distribution()`: Analisi distribuzione classi
  - File: **~470 righe**

- âœ… **1.4**: Creato `tests/test_training_phase1.py` con test suite pytest
  - Test `TrainingConfig`: creazione, validazione, paths, factory
  - Test `FocalLoss`: forward, backward, alpha weighting, reduction
  - Test utilities: split stratificato, class weights, metriche
  - File: **~450 righe**, 30+ test cases

- âœ… **1.5**: Aggiornato `src/training/__init__.py` con exports
  - Tutti i moduli esportati correttamente
  - `__all__` completo per import puliti

### Deliverable:
âœ… Moduli riutilizzabili pronti per l'integrazione  
âœ… Test suite completa per validazione  
âœ… Documentazione inline completa con esempi

### Note Tecniche:
- Usare `uv run python` per tutti i comandi Python
- Test imports con path assoluti (no modifica sys.path)
- Focal Loss threshold separato per ratio monitoring (20.0 vs 1.15)
- Class weights normalizzati (somma = num_classes)

---

## âœ… FASE 2: Best Model Tracking [COMPLETATA]
**Obiettivo**: Salvare solo il miglior modello basato su balanced_accuracy

### Task Completati:
- âœ… **2.1**: Creato `src/training/checkpoint.py` con classe `ModelCheckpoint`
  - Traccia best metric (default: balanced_accuracy)
  - Salva solo quando migliora, rimuove vecchio best
  - Path: `best_model_{format}_{model}_fold{k}.pth`
  - Buffer history con tutte le metriche
  - Save/Load checkpoint con optimizer state
  - Factory: `create_checkpoint_from_config()`
  - File: **~330 righe**

### Deliverable:
âœ… ModelCheckpoint pronto per integrazione nel training loop  
âœ… Test pytest: 9 test cases in `tests/test_training_phase2.py`

### Note:
- Test con simulazione 5 epoche: salva solo epoch 1 e 3 (miglioramenti)
- Checkpoint include: model state, optimizer state, metrics, timestamp

---

## âœ… FASE 3: Early Stopping Avanzato [COMPLETATA]
**Obiettivo**: Implementare early stopping con recupero pesi epoca trigger - patience

### Task Completati:
- âœ… **3.1**: Creato `src/training/early_stopping.py` con classe `EarlyStopping`
  - Delta loss + Train/Val ratio monitoring
  - Buffer ultimi N stati modello (N=patience) con deque
  - Ripristino pesi al best epoch o trigger-patience
  - Due modalitÃ  stop: patience esaurita o ratio violations
  - History tracking per analisi post-training
  - Factory: `create_early_stopping_from_config()`
  - File: **~350 righe**

### Deliverable:
âœ… EarlyStopping pronto per integrazione nel training loop  
âœ… Test pytest: 11 test cases in `tests/test_training_phase3.py`

### Note:
- Test 1: Patience esaurita dopo 3 epoche no improvement
- Test 2: Ratio violations detection (overfitting)
- Test 3: Training completo senza trigger
- Buffer usa deep copy per sicurezza

---

## âœ… FASE 4: K-Fold Cross Validation [TASK 4.2 COMPLETATO]
**Obiettivo**: K-fold mantenendo distribuzione classi, test set separato

### Task:
- âœ… **4.1**: ~~Creare funzione stratified_train_val_test_split()~~ GIÃ€ IN FASE 1
- âœ… **4.2**: Creato `src/training/kfold_trainer.py` con classe `KFoldTrainer`
  - Loop su K folds con StratifiedKFold
  - Crea Subset per train/val per ogni fold
  - Integra ModelCheckpoint e EarlyStopping per fold
  - Salva modello per fold: `best_model_{format}_{model}_fold{k}.pth`
  - Aggrega metriche: mean Â± std Â± min Â± max
  - Helper: `get_best_fold()`, `load_fold_model()`
  - Factory: `save_kfold_summary()` per report completo
  - File: **~420 righe**
- â¸ï¸ **4.3**: Modificare `train_llm.py` per usare KFoldTrainer

### Deliverable:
Training con k-fold, k modelli salvati, metriche aggregate  
âœ… Test pytest: 9 test cases in `tests/test_training_phase4.py`

### Note Test:
- 3 fold su 100 samples: balanced_accuracy mean=0.53 Â± 0.09
- Class distribution mantenuta (~52% vs ~48% in ogni fold)
- Modelli salvati correttamente in output/models/

---

## ğŸ­ FASE 5: Ensemble Prediction [PIANIFICATA]
**Obiettivo**: Usare ensemble dei k modelli per predizione/explainability

### Task:
- â¸ï¸ **5.1**: Creare `EnsembleModel` in `src/models/ensemble.py`
  - Carica k modelli da fold
  - Averaging o voting per predizione
- â¸ï¸ **5.2**: Modificare `eval_model.py` per usare ensemble
- â¸ï¸ **5.3**: Modificare `extract_explainability.py` per usare ensemble (o best fold)

### Deliverable:
Sistema ensemble funzionante

---

## ğŸ¯ FASE 6: Focal Loss Integration [PIANIFICATA]
**Obiettivo**: Focal Loss come opzione da command line

### Task:
- â¸ï¸ **6.1**: ~~Implementare Focal Loss~~ âœ… GIÃ€ IN FASE 1
- â¸ï¸ **6.2**: Aggiungere parametro `--loss-function` a `train_llm.py` (choices: focal, ce)
- â¸ï¸ **6.3**: Factory function per creare loss appropriata âœ… GIÃ€ IN FASE 1
- â¸ï¸ **6.4**: Test confronto focal vs crossentropy âœ… GIÃ€ IN FASE 1

### Deliverable:
Focal loss selezionabile, default focal

---

## ğŸ“ FASE 7: Logging e Script Updates [PIANIFICATA]
**Obiettivo**: Log completi e redirect su file negli script bash

### Task:
- â¸ï¸ **7.1**: Creare logger testuale in `src/training/logger.py`
  - Salva in `output/logs/training_{timestamp}.log`
  - Print a schermo + file simultaneo
- â¸ï¸ **7.2**: Aggiornare script bash per redirect output
  - `launch_run_train_eval` â†’ tee `output/logs/train_{timestamp}.log`
  - `run_explainability.sh` â†’ tee `output/logs/xai_{timestamp}.log`

### Deliverable:
Logging completo, tutto tracciato su file

---

## ğŸ§ª FASE 8: Testing e Validation [PIANIFICATA]
**Obiettivo**: Verificare tutto funziona end-to-end

### Task:
- â¸ï¸ **8.1**: Test completo k-fold con focal loss
- â¸ï¸ **8.2**: Verificare early stopping e recupero pesi
- â¸ï¸ **8.3**: Test ensemble prediction
- â¸ï¸ **8.4**: Documentazione in `docs/ADVANCED_TRAINING.md`

### Deliverable:
Sistema completo testato e documentato

---

## ğŸ¯ Ordine di Esecuzione
1. âœ… **FASE 1** (Setup) â†’ Base per tutto [COMPLETATA]
2. âš ï¸ **FASE 2** (Best Model) â†’ Riduce spazio disco subito [PROSSIMA]
3. â¸ï¸ **FASE 3** (Early Stop) â†’ Migliora qualitÃ  training
4. â¸ï¸ **FASE 4** (K-Fold) â†’ Core functionality
5. â¸ï¸ **FASE 6** (Focal Loss) â†’ Parallelo a Fase 4, indipendente
6. â¸ï¸ **FASE 5** (Ensemble) â†’ Dipende da Fase 4
7. â¸ï¸ **FASE 7** (Logging) â†’ Polish
8. â¸ï¸ **FASE 8** (Testing) â†’ Validazione finale

---

## âœ… Conferme Finali
- âœ… K-fold: k=10 default, test stratificato separato (20%)
- âœ… Best model: Solo balanced_accuracy, un file per fold
- âœ… Early stopping: epoca = trigger - patience
- âœ… Focal loss: Default, parametri standard (Î±=0.25, Î³=2.0)
- âœ… Ensemble: Media predizioni dei k modelli
- âœ… Mantieni opzione training semplice (non k-fold) per sviluppo rapido
- âœ… Test pytest per ogni fase

---

## ğŸ“¦ File Creati
```
src/training/
â”œâ”€â”€ __init__.py              [Aggiornato con exports]
â”œâ”€â”€ config.py                [~350 righe] TrainingConfig
â”œâ”€â”€ focal_loss.py            [~360 righe] FocalLoss
â”œâ”€â”€ utils.py                 [~470 righe] Split, metrics, weights
â”œâ”€â”€ checkpoint.py            [~330 righe] ModelCheckpoint [FASE 2]
â”œâ”€â”€ early_stopping.py        [~350 righe] EarlyStopping [FASE 3]
â””â”€â”€ kfold_trainer.py         [~420 righe] KFoldTrainer [FASE 4]

tests/
â”œâ”€â”€ test_training_phase1.py  [~450 righe] 23 test cases
â”œâ”€â”€ test_training_phase2.py  [~240 righe]  9 test cases
â”œâ”€â”€ test_training_phase3.py  [~220 righe] 11 test cases
â””â”€â”€ test_training_phase4.py  [~280 righe]  9 test cases
```

**Totale FASE 1-4**: ~2730 righe codice + ~1190 righe test = **3920 righe**  
**52 test cases pytest, tutti passing âœ…**

---

Vuoi mantenere anche l'opzione di training "semplice" (senza k-fold) per test rapidi?
Parti da quale FASE? Suggerisco FASE 1 per avere le basi pronte.
Dammi il via libera e partiamo dalla FASE 1! ğŸš€