ğŸ“‹ Piano Lavori - Training Avanzato

## ğŸ“Š STATO AVANZAMENTO
- **Ultimo aggiornamento**: 9 Ottobre 2025
- **Branch**: `advanced-training`
- **Fase corrente**: FASE 4 - COMPLETATA âœ…

---

## âœ… FASE 1: Setup Configurazione e Utilities [COMPLETATA]
**Obiettivo**: Creare infrastruttura base

### Task Completati:
- âœ… **1.1**: Creato `src/training/config.py` con classe `TrainingConfig`
  - Dataclass con tutti i parametri di training
  - K-Fold CV: `use_kfold`, `n_folds=10`, stratificato
  - Focal Loss: `focal_alpha=[0.25, 0.75]`, `focal_gamma=2.0`
  - Early Stopping: patience=5, delta+ratio monitoring
  - Best model tracking: balanced_accuracy
  - Path management integrato con struttura LEGOLAS
  - Factory functions: `create_default_config()`, `create_kfold_config()`
  - Validazione configurazione con `validate()`
  - File: **~350 righe**

- âœ… **1.2**: Creato `src/training/focal_loss.py` con implementazione Focal Loss
  - Classe `FocalLoss(nn.Module)` completa
  - Formula: `FL(p_t) = -Î±_t * (1 - p_t)^Î³ * log(p_t)`
  - Supporto alpha (class weights) e gamma (focusing parameter)
  - Reduction modes: mean, sum, none
  - Factory function: `create_focal_loss()`
  - Integration helper: `create_loss_from_config()`
  - Test comparativi Focal vs CrossEntropy
  - File: **~360 righe**

- âœ… **1.3**: Creato `src/training/utils.py` con funzioni utility
  - `stratified_train_val_test_split()`: Split stratificato train/val/test
  - `create_stratified_kfold()`: StratifiedKFold per CV
  - `compute_class_weights()`: Calcolo pesi per classi sbilanciate
  - `compute_metrics()`: Accuracy, balanced_accuracy, precision, recall, F1
  - `compute_detailed_metrics()`: Metriche + confusion matrix + report
  - `save_metrics()` / `load_metrics()`: I/O metriche JSON
  - `analyze_class_distribution()`: Analisi distribuzione classi
  - File: **~470 righe**

- âœ… **1.4**: Creato `tests/test_training_phase1.py` con test suite pytest
  - Test `TrainingConfig`: creazione, validazione, paths, factory
  - Test `FocalLoss`: forward, backward, alpha weighting, reduction
  - Test utilities: split stratificato, class weights, metriche
  - File: **~450 righe**, 30+ test cases

- âœ… **1.5**: Aggiornato `src/training/__init__.py` con exports
  - Tutti i moduli esportati correttamente
  - `__all__` completo per import puliti

### Deliverable:
âœ… Moduli riutilizzabili pronti per l'integrazione  
âœ… Test suite completa per validazione  
âœ… Documentazione inline completa con esempi

### Note Tecniche:
- Usare `uv run python` per tutti i comandi Python
- Test imports con path assoluti (no modifica sys.path)
- Focal Loss threshold separato per ratio monitoring (20.0 vs 1.15)
- Class weights normalizzati (somma = num_classes)

---

## âœ… FASE 2: Best Model Tracking [COMPLETATA]
**Obiettivo**: Salvare solo il miglior modello basato su balanced_accuracy

### Task Completati:
- âœ… **2.1**: Creato `src/training/checkpoint.py` con classe `ModelCheckpoint`
  - Traccia best metric (default: balanced_accuracy)
  - Salva solo quando migliora, rimuove vecchio best
  - Path: `best_model_{format}_{model}_fold{k}.pth`
  - Buffer history con tutte le metriche
  - Save/Load checkpoint con optimizer state
  - Factory: `create_checkpoint_from_config()`
  - File: **~330 righe**

### Deliverable:
âœ… ModelCheckpoint pronto per integrazione nel training loop  
âœ… Test pytest: 9 test cases in `tests/test_training_phase2.py`

### Note:
- Test con simulazione 5 epoche: salva solo epoch 1 e 3 (miglioramenti)
- Checkpoint include: model state, optimizer state, metrics, timestamp

---

## âœ… FASE 3: Early Stopping Avanzato [COMPLETATA]
**Obiettivo**: Implementare early stopping con recupero pesi epoca trigger - patience

### Task Completati:
- âœ… **3.1**: Creato `src/training/early_stopping.py` con classe `EarlyStopping`
  - Delta loss + Train/Val ratio monitoring
  - Buffer ultimi N stati modello (N=patience) con deque
  - Ripristino pesi al best epoch o trigger-patience
  - Due modalitÃ  stop: patience esaurita o ratio violations
  - History tracking per analisi post-training
  - Factory: `create_early_stopping_from_config()`
  - File: **~350 righe**

### Deliverable:
âœ… EarlyStopping pronto per integrazione nel training loop  
âœ… Test pytest: 11 test cases in `tests/test_training_phase3.py`

### Note:
- Test 1: Patience esaurita dopo 3 epoche no improvement
- Test 2: Ratio violations detection (overfitting)
- Test 3: Training completo senza trigger
- Buffer usa deep copy per sicurezza

---

## âœ… FASE 4: K-Fold Cross Validation [COMPLETATA]
**Obiettivo**: K-fold mantenendo distribuzione classi, test set separato

### Task:
- âœ… **4.1**: ~~Creare funzione stratified_train_val_test_split()~~ GIÃ€ IN FASE 1
- âœ… **4.2**: Creato `src/training/kfold_trainer.py` con classe `KFoldTrainer`
  - Loop su K folds con StratifiedKFold
  - Crea Subset per train/val per ogni fold
  - Integra ModelCheckpoint e EarlyStopping per fold
  - Salva modello per fold: `best_model_{format}_{model}_fold{k}.pth`
  - Aggrega metriche: mean Â± std Â± min Â± max
  - Helper: `get_best_fold()`, `load_fold_model()`
  - Factory: `save_kfold_summary()` per report completo
  - File: **~420 righe**
- âœ… **4.3**: Modificato `train_llm.py` per usare KFoldTrainer (8 sub-task completati)

### Deliverable:
Training con k-fold, k modelli salvati, metriche aggregate  
âœ… Test pytest: 9 test cases in `tests/test_training_phase4.py`

### Note Test:
- 3 fold su 100 samples: balanced_accuracy mean=0.53 Â± 0.09
- Class distribution mantenuta (~52% vs ~48% in ogni fold)
- Modelli salvati correttamente in output/models/

---

## ğŸ­ FASE 5: Ensemble Prediction [PIANIFICATA]
**Obiettivo**: Usare ensemble dei k modelli per predizione/explainability

### Task:
- â¸ï¸ **5.1**: Creare `EnsembleModel` in `src/models/ensemble.py`
  - Carica k modelli da fold
  - Averaging o voting per predizione
- â¸ï¸ **5.2**: Modificare `eval_model.py` per usare ensemble
- â¸ï¸ **5.3**: Modificare `extract_explainability.py` per usare ensemble (o best fold)

### Deliverable:
Sistema ensemble funzionante

---

## ğŸ¯ FASE 6: Focal Loss Integration [PIANIFICATA]
**Obiettivo**: Focal Loss come opzione da command line

### Task:
- â¸ï¸ **6.1**: ~~Implementare Focal Loss~~ âœ… GIÃ€ IN FASE 1
- â¸ï¸ **6.2**: Aggiungere parametro `--loss-function` a `train_llm.py` (choices: focal, ce)
- â¸ï¸ **6.3**: Factory function per creare loss appropriata âœ… GIÃ€ IN FASE 1
- â¸ï¸ **6.4**: Test confronto focal vs crossentropy âœ… GIÃ€ IN FASE 1

### Deliverable:
Focal loss selezionabile, default focal

---

## ğŸ“ FASE 7: Logging e Script Updates [PIANIFICATA]
**Obiettivo**: Log completi e redirect su file negli script bash

### Task:
- â¸ï¸ **7.1**: Creare logger testuale in `src/training/logger.py`
  - Salva in `output/logs/training_{timestamp}.log`
  - Print a schermo + file simultaneo
- â¸ï¸ **7.2**: Aggiornare script bash per redirect output
  - `launch_run_train_eval` â†’ tee `output/logs/train_{timestamp}.log`
  - `run_explainability.sh` â†’ tee `output/logs/xai_{timestamp}.log`

### Deliverable:
Logging completo, tutto tracciato su file

---

## ğŸ§ª FASE 8: Testing e Validation [PIANIFICATA]
**Obiettivo**: Verificare tutto funziona end-to-end

### Task:
- â¸ï¸ **8.1**: Test completo k-fold con focal loss
- â¸ï¸ **8.2**: Verificare early stopping e recupero pesi
- â¸ï¸ **8.3**: Test ensemble prediction
- â¸ï¸ **8.4**: Documentazione in `docs/ADVANCED_TRAINING.md`

### Deliverable:
Sistema completo testato e documentato

---

## ğŸ¯ Ordine di Esecuzione
1. âœ… **FASE 1** (Setup) â†’ Base per tutto [COMPLETATA]
2. âœ… **FASE 2** (Best Model) â†’ Riduce spazio disco subito [COMPLETATA]
3. âœ… **FASE 3** (Early Stop) â†’ Migliora qualitÃ  training [COMPLETATA]
4. âœ… **FASE 4** (K-Fold) â†’ Core functionality [COMPLETATA]
   - âœ… 4.1: stratified_train_val_test_split
   - âœ… 4.2: KFoldTrainer
   - âœ… 4.3: Integrazione train_llm.py (8 sub-task)
5. â¸ï¸ **FASE 5** (Ensemble) â†’ Dipende da Fase 4
6. â¸ï¸ **FASE 6** (Focal Loss) â†’ Parallelo a Fase 4, indipendente
7. â¸ï¸ **FASE 7** (Logging) â†’ Polish
8. â¸ï¸ **FASE 8** (Testing) â†’ Validazione finale

---

## âœ… Conferme Finali
- âœ… K-fold: k=10 default, test stratificato separato (20%)
- âœ… Best model: Solo balanced_accuracy, un file per fold
- âœ… Early stopping: epoca = trigger - patience
- âœ… Focal loss: Default, parametri standard (Î±=0.25, Î³=2.0)
- âœ… Ensemble: Media predizioni dei k modelli
- âœ… Mantieni opzione training semplice (non k-fold) per sviluppo rapido
- âœ… Test pytest per ogni fase

---

## ğŸ“¦ File Creati
```
src/training/
â”œâ”€â”€ __init__.py              [Aggiornato con exports]
â”œâ”€â”€ config.py                [~350 righe] TrainingConfig
â”œâ”€â”€ focal_loss.py            [~360 righe] FocalLoss
â”œâ”€â”€ utils.py                 [~470 righe] Split, metrics, weights
â”œâ”€â”€ checkpoint.py            [~330 righe] ModelCheckpoint [FASE 2]
â”œâ”€â”€ early_stopping.py        [~350 righe] EarlyStopping [FASE 3]
â”œâ”€â”€ kfold_trainer.py         [~420 righe] KFoldTrainer [FASE 4]
â””â”€â”€ train_llm.py             [~575 righe] Main training script [FASE 4.3]

tests/
â”œâ”€â”€ test_training_phase1.py    [~450 righe] 23 test cases
â”œâ”€â”€ test_training_phase2.py    [~240 righe]  9 test cases
â”œâ”€â”€ test_training_phase3.py    [~220 righe] 11 test cases
â”œâ”€â”€ test_training_phase4.py    [~280 righe]  9 test cases
â”œâ”€â”€ test_training_phase4_3_1.py [~252 righe] 11 test cases [FASE 4.3.1]
â”œâ”€â”€ test_training_phase4_3_2.py [~350 righe]  3 test cases [FASE 4.3.2]
â”œâ”€â”€ test_training_phase4_3_3.py [~200 righe]  9 test cases [FASE 4.3.3]
â””â”€â”€ test_training_phase4_3_4.py [~320 righe]  8 test cases [FASE 4.3.4]
```

**Totale FASE 1-4.3.4**: ~3705 righe codice + ~2312 righe test = **6017 righe**  
**83 test cases pytest, tutti passing âœ…**

---

## ğŸ”§ FASE 4.3 - Integrazione train_llm.py

### âœ… 4.3.1 - Gestione CLI Arguments e TrainingConfig [COMPLETATO]
**Decisioni:**
- âœ… Argparse (resto progetto lo usa)
- âœ… CLI args: model_name, story_format, use_kfold, n_folds, use_focal_loss, focal_alpha, focal_gamma, patience, epochs
- âœ… Senza --use_kfold â†’ training semplice (backward compatibility)
- âœ… No config YAML, solo CLI

**Implementazione:**
- âœ… Aggiunto argparse con 10 parametri CLI
- âœ… Funzione `parse_args()` per parsing argomenti
- âœ… Funzione `create_training_config(args)` per creare TrainingConfig
- âœ… Sostituiti STORY_FORMAT, LEARNING_RATE, BATCH con config
- âœ… Mapping: epochsâ†’num_epochs, patienceâ†’early_stopping_patience, use_focal_lossâ†’loss_function
- âœ… Test: 11 test cases, tutti passing âœ…
- âœ… File: tests/test_training_phase4_3_1.py (~260 righe)

### âœ… 4.3.2 - Refactor pre_train() - Signature e Early Stopping [COMPLETATO]
**Decisioni:**
- âœ… Tutto su TrainingConfig (rimuovi num_epochs, min_loss, model_output_basename)
- âœ… Rimuovi start_epoch (sempre 0)
- âœ… Nome modello: config.get_model_filename(fold)
- âœ… Accelerator globale

**Implementazione:**
- âœ… Nuova signature: pre_train(model, optimizer, train_dataloader, val_dataloader, scheduler, criterion, accelerator, config, checkpoint, early_stopping, fold)
- âœ… Rimosso patience_counter custom, usato EarlyStopping class
- âœ… Compute metrics con balanced_accuracy come metrica principale
- âœ… ModelCheckpoint.update() per salvare best model
- âœ… EarlyStopping.update() + should_stop() per controllo
- âœ… restore_weights() per ripristinare best model al trigger
- âœ… Logging dettagliato per epoch (train/val loss e balanced_accuracy)
- âœ… Test: 3 test cases, tutti passing âœ…
- âœ… File: tests/test_training_phase4_3_2.py (~350 righe)

### âœ… 4.3.3 - Loss Function [COMPLETATO]
**Decisioni:**
- âœ… Class weights SOLO per CrossEntropyLoss (calcolo automatico)
- âœ… Focal Loss: gestisce giÃ  pesi con Î±/Î³ (no class weights)
- âœ… Metodo calcolo pesi: fisso 'balanced', no parametro CLI

**Implementazione:**
- âœ… Import `create_loss_from_config()` e `compute_class_weights()`
- âœ… Path Focal Loss: usa `create_loss_from_config(config)` con Î±/Î³ da config
- âœ… Path Cross Entropy: calcola class weights con metodo 'balanced', crea `nn.CrossEntropyLoss(weight=weights_tensor)`
- âœ… Logging configurazione loss function all'avvio
- âœ… Test: 9 test cases, tutti passing âœ…
- âœ… File: tests/test_training_phase4_3_3.py (~200 righe)

### âœ… 4.3.4 - Checkpoint e Model Saving [COMPLETATO]
**Decisioni:**
- âœ… Metrica: balanced_accuracy
- âœ… History gestito da checkpoint.save_history()
- âœ… Stampe centralizzate

**Implementazione:**
- âœ… Salvataggio automatic history alla fine del training con `checkpoint.save_history()`
- âœ… Logging info early stopping se triggerato (trigger epoch, best val loss, wait count)
- âœ… Summary finale con best epoch, best balanced_accuracy, path modello salvato
- âœ… History salvata in JSON: `checkpoint_history.json` (o `checkpoint_history_fold{k}.json` per K-Fold)
- âœ… Test: 8 test cases, tutti passing âœ…
- âœ… File: tests/test_training_phase4_3_4.py (~320 righe)

### âœ… 4.3.5 - K-Fold Wrapper [COMPLETATO]
**Decisioni:**
- âœ… Usa KFoldTrainer class (FASE 4.0) invece di logica custom
- âœ… Conditional routing: if config.use_kfold â†’ KFoldTrainer else â†’ simple training
- âœ… Model factory per creare modelli freschi per ogni fold
- âœ… Training function wrapper per chiamare pre_train() per ogni fold
- âœ… Dataset combinato da X_train + X_val per K-Fold

**Implementazione:**
- âœ… Import `KFoldTrainer` da `src.training.kfold_trainer`
- âœ… Conditional routing nella sezione main basato su `config.use_kfold`
- âœ… Model factory function: gestisce sia GPT2 che BERT-based models
- âœ… Train function wrapper: setup optimizer/scheduler/dataloader per fold, chiama pre_train()
- âœ… Aggregazione risultati: mean Â± std balanced_accuracy
- âœ… Backward compatibility: simple training preservato senza modifiche
- âœ… No test specifici (logica giÃ  coperta da 9 test FASE 4.0)

### âœ… 4.3.6 - Data Loading e Split Stratificato [COMPLETATO]
**Decisioni:**
- âœ… Test set giÃ  separato upstream (train.pickle / test.pickle) â†’ manteniamo
- âœ… Split train/val giÃ  stratificato con sklearn â†’ manteniamo (funziona bene)
- âœ… Label mapping generico: `CLS_0`, `CLS_1` invece di label specifiche
- âœ… Salva label2id/id2label in JSON per eval_model.py e extract_explainability.py

**Implementazione:**
- âœ… Import `analyze_class_distribution` da utils
- âœ… Creazione label mapping generico per export (`CLS_0`, `CLS_1`)
- âœ… Salvataggio JSON: `output/reports/label_mapping.json`
- âœ… Formato: `{"label2id": {"CLS_0": 0, ...}, "id2label": {"0": "CLS_0", ...}, "num_classes": 2}`
- âœ… Logging distribuzione classi per train/val/test set
- âœ… No test specifici (logica semplice: JSON save + print stats)

**Note:**
- Manteniamo `train_test_split` sklearn (giÃ  stratificato, no benefici a cambiare)
- `stratified_train_val_test_split()` da FASE 1 rimane inutilizzato â†’ vedi Refactoring Futuro

### âœ… 4.3.7 - Test di Integrazione [COMPLETATO]
**Decisioni:**
- âœ… Test con dati mock per velocitÃ 
- âœ… Test path corretti file salvati
- âœ… Test integrazione K-Fold routing
- âœ… No test GPU (troppo specifici)

**Implementazione:**
- âœ… Test implementati dall'utente
- âœ… Tutti i test passano
- âœ… Copertura completa funzionalitÃ 

### âœ… 4.3.8 - Documentazione [COMPLETATO]
**Decisioni:**
- âœ… File separato: docs/TRAIN_LLM_INTEGRATION.md
- âœ… Riferimento nel PIANO_LAVORI
- âœ… Esempi bash completi
- âœ… Best practices e troubleshooting

**Implementazione:**
- âœ… Creato `docs/TRAIN_LLM_INTEGRATION.md` (~600 righe)
- âœ… Sezioni:
  * Panoramica funzionalitÃ 
  * Utilizzo CLI e script bash
  * Parametri completi
  * Output e file generati
  * Workflow completo
  * Esempi pratici (4 scenari)
  * Interpretazione output console
  * Best practices
  * Troubleshooting
  * Riferimenti
- âœ… Esempi per ogni scenario: simple, K-Fold, Focal, K-Fold+Focal
- âœ… Guida scelta training mode e loss function
- âœ… Tuning hyperparameters e gestione risorse

**Riferimento completo:** [TRAIN_LLM_INTEGRATION.md](./TRAIN_LLM_INTEGRATION.md)

---

## ğŸ”„ REFACTORING FUTURO

### Codice Inutilizzato da Rimuovere/Consolidare

**1. `stratified_train_val_test_split()` in `src/training/utils.py`**
- **Stato**: Implementata in FASE 1.3, mai utilizzata
- **Motivo**: `train_llm.py` usa `train_test_split` di sklearn (giÃ  stratificato, test set giÃ  separato upstream)
- **Azione futura**: 
  - Opzione A: Rimuovere se confermato che non serve
  - Opzione B: Refactor pipeline XES per usarla upstream (split train/val/test prima del pickle)
- **PrioritÃ **: Bassa (non impatta funzionalitÃ )

**2. Possibili Duplicazioni da Verificare**
- **Da verificare**: Controllare se ci sono altre utility FASE 1 non utilizzate
- **Action**: Audit completo dopo FASE 8 (quando tutto Ã¨ integrato)

### Architettura Modelli - Refactoring da Multi-Classe a Generico

**3. Neural Network Classes - âœ… COMPLETATO (9 Ottobre 2025)**
- **File**: `src/models/neural_network.py`
- **Problema originale**: 
  - `LongFormerMultiClassificationHeads`: 8 classi hardcoded nel layer finale
  - `SimpleGPT2SequenceClassifier`: Riceve `num_classes` ma in `train_llm.py` era chiamato con 8 hardcoded
  - Progetto originale era multi-classe (8 DRG), ora deve supportare N-classi generico
- **Soluzione implementata**:
  - âœ… Aggiunto parametro `num_classes` a `LongFormerMultiClassificationHeads.__init__(num_classes=8)`
  - âœ… Default a 8 per backward compatibility con codice legacy
  - âœ… Aggiornato `train_llm.py` (linee 543-563) per usare `config.num_classes`
  - âœ… Aggiornato `model_factory` (linee 620-637) per usare `config.num_classes`
  - âœ… Ora completamente generico: supporta 2, 3, 8, N classi
- **Testing**: Verificare con classificazione binaria (2 classi) e multi-classe (3+)
- **Riferimento**: Bug #4 durante test K-Fold, refactoring 9 Ottobre 2025

---

Vuoi mantenere anche l'opzione di training "semplice" (senza k-fold) per test rapidi?
Parti da quale FASE? Suggerisco FASE 1 per avere le basi pronte.
Dammi il via libera e partiamo dalla FASE 1! ğŸš€