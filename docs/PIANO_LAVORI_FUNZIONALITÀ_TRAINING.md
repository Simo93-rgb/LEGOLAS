ğŸ“‹ Piano Lavori - Training Avanzato

## ğŸ“Š STATO AVANZAMENTO
- **Ultimo aggiornamento**: 10 Ottobre 2025
- **Branch**: `advanced-training`
- **Fase corrente**: FASE 4 - COMPLETATA âœ…
- **Prossima**: FASE 5 - Ensemble Prediction

---

## âœ… FASE 1: Setup Configurazione e Utilities [COMPLETATA]
**Obiettivo**: Creare infrastruttura base

### Task Completati:
- âœ… **1.1**: Creato `src/training/config.py` con classe `TrainingConfig`
  - Dataclass con tutti i parametri di training
  - K-Fold CV: `use_kfold`, `n_folds=10`, stratificato
  - Focal Loss: `focal_alpha=[0.25, 0.75]`, `focal_gamma=2.0`
  - Early Stopping: patience=5, delta+ratio monitoring
  - Best model tracking: balanced_accuracy
  - Path management integrato con struttura LEGOLAS
  - Factory functions: `create_default_config()`, `create_kfold_config()`
  - Validazione configurazione con `validate()`
  - File: **~350 righe**

- âœ… **1.2**: Creato `src/training/focal_loss.py` con implementazione Focal Loss
  - Classe `FocalLoss(nn.Module)` completa
  - Formula: `FL(p_t) = -Î±_t * (1 - p_t)^Î³ * log(p_t)`
  - Supporto alpha (class weights) e gamma (focusing parameter)
  - Reduction modes: mean, sum, none
  - Factory function: `create_focal_loss()`
  - Integration helper: `create_loss_from_config()`
  - Test comparativi Focal vs CrossEntropy
  - File: **~360 righe**

- âœ… **1.3**: Creato `src/training/utils.py` con funzioni utility
  - `stratified_train_val_test_split()`: Split stratificato train/val/test
  - `create_stratified_kfold()`: StratifiedKFold per CV
  - `compute_class_weights()`: Calcolo pesi per classi sbilanciate
  - `compute_metrics()`: Accuracy, balanced_accuracy, precision, recall, F1
  - `compute_detailed_metrics()`: Metriche + confusion matrix + report
  - `save_metrics()` / `load_metrics()`: I/O metriche JSON
  - `analyze_class_distribution()`: Analisi distribuzione classi
  - File: **~470 righe**

- âœ… **1.4**: Creato `tests/test_training_phase1.py` con test suite pytest
  - Test `TrainingConfig`: creazione, validazione, paths, factory
  - Test `FocalLoss`: forward, backward, alpha weighting, reduction
  - Test utilities: split stratificato, class weights, metriche
  - File: **~450 righe**, 30+ test cases

- âœ… **1.5**: Aggiornato `src/training/__init__.py` con exports
  - Tutti i moduli esportati correttamente
  - `__all__` completo per import puliti

### Deliverable:
âœ… Moduli riutilizzabili pronti per l'integrazione  
âœ… Test suite completa per validazione  
âœ… Documentazione inline completa con esempi

### Note Tecniche:
- Usare `uv run python` per tutti i comandi Python
- Test imports con path assoluti (no modifica sys.path)
- Focal Loss threshold separato per ratio monitoring (20.0 vs 1.15)
- Class weights normalizzati (somma = num_classes)

---

## âœ… FASE 2: Best Model Tracking [COMPLETATA]
**Obiettivo**: Salvare solo il miglior modello basato su balanced_accuracy

### Task Completati:
- âœ… **2.1**: Creato `src/training/checkpoint.py` con classe `ModelCheckpoint`
  - Traccia best metric (default: balanced_accuracy)
  - Salva solo quando migliora, rimuove vecchio best
  - Path: `best_model_{format}_{model}_fold{k}.pth`
  - Buffer history con tutte le metriche
  - Save/Load checkpoint con optimizer state
  - Factory: `create_checkpoint_from_config()`
  - File: **~330 righe**

### Deliverable:
âœ… ModelCheckpoint pronto per integrazione nel training loop  
âœ… Test pytest: 9 test cases in `tests/test_training_phase2.py`

### Note:
- Test con simulazione 5 epoche: salva solo epoch 1 e 3 (miglioramenti)
- Checkpoint include: model state, optimizer state, metrics, timestamp

---

## âœ… FASE 3: Early Stopping Avanzato [COMPLETATA]
**Obiettivo**: Implementare early stopping con recupero pesi epoca trigger - patience

### Task Completati:
- âœ… **3.1**: Creato `src/training/early_stopping.py` con classe `EarlyStopping`
  - Delta loss + Train/Val ratio monitoring
  - Buffer ultimi N stati modello (N=patience) con deque
  - Ripristino pesi al best epoch o trigger-patience
  - Due modalitÃ  stop: patience esaurita o ratio violations
  - History tracking per analisi post-training
  - Factory: `create_early_stopping_from_config()`
  - File: **~350 righe**

### Deliverable:
âœ… EarlyStopping pronto per integrazione nel training loop  
âœ… Test pytest: 11 test cases in `tests/test_training_phase3.py`

### Note:
- Test 1: Patience esaurita dopo 3 epoche no improvement
- Test 2: Ratio violations detection (overfitting)
- Test 3: Training completo senza trigger
- Buffer usa deep copy per sicurezza

---

## âœ… FASE 4: K-Fold Cross Validation [COMPLETATA]
**Obiettivo**: K-fold mantenendo distribuzione classi, test set separato

### Task:
- âœ… **4.1**: ~~Creare funzione stratified_train_val_test_split()~~ GIÃ€ IN FASE 1
- âœ… **4.2**: Creato `src/training/kfold_trainer.py` con classe `KFoldTrainer`
  - Loop su K folds con StratifiedKFold
  - Crea Subset per train/val per ogni fold
  - Integra ModelCheckpoint e EarlyStopping per fold
  - Salva modello per fold: `best_model_{format}_{model}_fold{k}.pth`
  - Aggrega metriche: mean Â± std Â± min Â± max
  - Helper: `get_best_fold()`, `load_fold_model()`
  - Factory: `save_kfold_summary()` per report completo
  - File: **~420 righe**
- âœ… **4.3**: Modificato `train_llm.py` per usare KFoldTrainer
  - **Dettagli completi**: Vedi sezione [FASE 4.3 - Integrazione train_llm.py](#-fase-43---integrazione-train_llmpy) in fondo al documento
  - **8 sub-task completati**: CLI args, pre_train refactor, loss function, checkpoint, K-Fold wrapper, data loading, test, documentazione
  - **Bug fixes**: 4 bug risolti durante test real-world
  - **Refactoring**: num_classes configurabile, logging K-Fold migliorato

### Deliverable:
âœ… Training con k-fold, k modelli salvati, metriche aggregate  
âœ… Test pytest: 9 test cases in `tests/test_training_phase4.py`  
âœ… Integration completa train_llm.py con tutte le nuove features

### Note Test:
- 3 fold su 100 samples: balanced_accuracy mean=0.53 Â± 0.09
- Class distribution mantenuta (~52% vs ~48% in ogni fold)
- Modelli salvati correttamente in output/models/
- Test real-world con 5-fold completato con successo
- Early stopping triggera correttamente su alcuni fold

---

## ğŸ­ FASE 5: Ensemble Prediction [IN PIANIFICAZIONE]
**Obiettivo**: Usare ensemble dei k modelli per predizione e explainability tramite averaging

### Motivazione Tecnica
**PerchÃ© Averaging e non Voting?**
- âœ… **Compatibile con XAI**: Averaging dei pesi permette di estrarre feature importance media
- âœ… **Integrated Gradients**: Algoritmo IG giÃ  implementato lavora su pesi â†’ media pesi dei k modelli
- âœ… **Consistenza**: Predizione e XAI usano stesso meccanismo (averaging)
- âŒ **Voting**: Non compatibile con estrazione pesi per XAI â†’ scartato

### Task:
- â¸ï¸ **5.1**: Creare `EnsembleModel` in `src/models/ensemble.py`
  - Carica k modelli da fold (paths in `output/models/{format}_{model}_kfold/fold_*/`)
  - Metodo `predict()`: averaging delle probabilitÃ  (softmax) dei k modelli
  - Metodo `get_averaged_weights()`: media dei pesi per XAI
  - Helper: `load_best_fold()` per caricare solo il miglior fold
- â¸ï¸ **5.2**: Modificare `eval_model.py` per usare ensemble
  - Parametro `--use_ensemble` per abilitare ensemble vs singolo modello
  - Se ensemble: carica tutti i fold, fa averaging
  - Se singolo: usa best fold (massima balanced_accuracy)
- â¸ï¸ **5.3**: Modificare `extract_explainability.py` per usare ensemble
  - Parametro `--use_ensemble` per abilitare ensemble
  - Averaging pesi modelli prima di applicare Integrated Gradients
  - Estrazione feature importance su modello medio

### Deliverable:
âœ… EnsembleModel class funzionante  
âœ… Eval e XAI con supporto ensemble  
âœ… Test pytest per ensemble averaging  
âœ… Documentazione integrazione ensemble

### Note Implementative:
- Averaging: `prob_avg = mean([model_i.predict(x) for i in range(k)])`
- Weights averaging: `W_avg = mean([model_i.state_dict() for i in range(k)])`
- CompatibilitÃ  IG: media pesi â†’ single model equivalente â†’ IG standard

---

## âœ… FASE 6: Focal Loss Integration [COMPLETATA]
**Obiettivo**: Focal Loss come opzione da command line

### Task Completati:
- âœ… **6.1**: Implementare Focal Loss â†’ Completato in FASE 1.2
- âœ… **6.2**: Parametro `--use_focal_loss` in `train_llm.py` â†’ Completato in FASE 4.3.1
- âœ… **6.3**: Factory function `create_loss_from_config()` â†’ Completato in FASE 1.2
- âœ… **6.4**: Test confronto focal vs crossentropy â†’ Completato in FASE 1.4

### Implementazione:
- CLI: `--use_focal_loss --focal_alpha 0.25 0.75 --focal_gamma 2.0`
- Default: Focal Loss abilitata per gestione classi sbilanciate
- CrossEntropy: `--use_focal_loss` NON specificato, calcola class weights automatici
- Parametri configurabili: Î± (alpha per classe), Î³ (focusing parameter)

### Deliverable:
âœ… Focal loss selezionabile da CLI  
âœ… Default focal, fallback CrossEntropy con class weights  
âœ… Test completi (9 test cases in test_training_phase4_3_3.py)

### Riferimenti:
- Implementazione: `src/training/focal_loss.py` (~360 righe)
- Integrazione: `src/training/train_llm.py` (FASE 4.3.3)
- Documentazione: [TRAIN_LLM_INTEGRATION.md](./TRAIN_LLM_INTEGRATION.md)

---

## ğŸ“ FASE 7: Logging su File (Script Bash) [DA FARE]
**Obiettivo**: Redirect output Python su file tramite script bash, mantenendo output console

### Motivazione
- âŒ **NO Logger Python**: Evita codice aggiuntivo e complessitÃ 
- âœ… **Bash `tee`**: Soluzione semplice, output duplicato (console + file)
- âœ… **Mantiene stampe real-time**: Nessuna modifica al codice Python

### Task:
- â¸ï¸ **7.1**: Aggiornare `scripts/launch_run_train_eval`
  - Aggiungere `tee` per salvare in `output/logs/train_${TIMESTAMP}.log`
  - Formato: `uv run python ... | tee output/logs/train_$(date +%Y%m%d_%H%M%S).log`
  - Mantiene output colorato e real-time a schermo
  
- â¸ï¸ **7.2**: Aggiornare `scripts/run_explainability.sh`
  - Aggiungere `tee` per salvare in `output/logs/xai_${TIMESTAMP}.log`
  - Stesso pattern: `uv run python ... | tee output/logs/xai_$(date +%Y%m%d_%H%M%S).log`

- â¸ï¸ **7.3**: Creare directory `output/logs/` se non esiste
  - Aggiungere `mkdir -p output/logs` nei script

### Esempio Implementazione:
```bash
# PRIMA
eval $CMD

# DOPO
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
mkdir -p output/logs
eval $CMD 2>&1 | tee "output/logs/train_${TIMESTAMP}.log"
```

### Deliverable:
âœ… Output salvato automaticamente in file con timestamp  
âœ… Console output preservato (nessuna modifica esperienza utente)  
âœ… No codice Python aggiuntivo

### Note:
- `tee`: duplica output (stdout + file)
- `2>&1`: redirect stderr a stdout (cattura anche errori)
- Timestamp: formato `YYYYMMDD_HHMMSS` per sorting automatico

---

## ğŸ§ª FASE 8: Testing, Validation e Documentazione [IN CORSO]
**Obiettivo**: Verificare funzionamento end-to-end e documentazione completa

### âœ… Task Completati:
- âœ… **8.1**: Test completo K-Fold con Focal Loss
  - Training eseguito con successo
  - Modelli salvati per ogni fold in `output/models/`
  - JSON metriche per ogni fold con history completo
  - **Risultato**: Funzionante, early stopping triggera correttamente

- âœ… **8.2**: Verificare Early Stopping e recupero pesi
  - Alcuni addestramenti hanno triggerato patience
  - Early stopping attivato correttamente
  - Ripristino pesi best epoch funzionante
  - **Risultato**: Funzionante, sistema robusto

### â¸ï¸ Task Rimanenti:
- â¸ï¸ **8.3**: Test Ensemble Prediction
  - Dipende da completamento FASE 5
  - Test averaging predizioni
  - Test averaging pesi per XAI

- â¸ï¸ **8.4**: Documentazione Completa (4 sub-task)

### ğŸ“š 8.4 - Documentazione Completa

#### â¸ï¸ **8.4.1**: Audit Documentazione Esistente
**Obiettivo**: Capire cosa c'Ã¨ nella cartella `docs/`

**Task**:
1. Leggere tutti i documenti in `docs/`
2. Creare summary per ogni documento:
   - Titolo e scopo
   - Contenuto principale
   - Stato (aggiornato/obsoleto/incompleto)
   - Dipendenze/riferimenti ad altri doc
3. Creare matrice documenti:
   - Quali si sovrappongono?
   - Quali hanno info obsolete?
   - Quali mancano?

**Output**: `docs/DOCUMENTATION_AUDIT.md` con summary completo

#### â¸ï¸ **8.4.2**: Pulizia Documentazione
**Obiettivo**: Rimuovere documenti inutili o duplicati

**Task**:
1. Identificare documenti da eliminare:
   - Obsoleti (info superate da refactoring)
   - Duplicati (stesse info in piÃ¹ file)
   - Temporary (guide intermedie non piÃ¹ rilevanti)
2. Eliminare file inutili
3. Archiviare in `docs/archive/` se necessario

**Output**: Cartella `docs/` pulita e organizzata

#### â¸ï¸ **8.4.3**: Aggiornamento Documentazione
**Obiettivo**: Portare in pari i documenti utili con lo stato del progetto

**Task**:
1. Per ogni documento utile:
   - Verificare accuratezza tecnica
   - Aggiornare comandi/path modificati
   - Aggiungere info mancanti (es: K-Fold, Focal Loss)
   - Correggere esempi obsoleti
2. Creare nuovi documenti se necessario:
   - User guide completa
   - API reference
   - Troubleshooting guide

**Output**: Documentazione aggiornata e accurata

#### â¸ï¸ **8.4.4**: README.md Principale
**Obiettivo**: README snello con link a documentazione dettagliata

**Struttura README**:
```markdown
# LEGOLAS Fork - Advanced Training & Explainability

## ğŸ“– Descrizione
Fork del progetto LEGOLAS con funzionalitÃ  avanzate...

## ğŸ‘¥ Autori e Crediti
### Progetto Originale: LEGOLAS
- **Citazione**: [Link articolo scientifico]
- **Repository originale**: [Link]

### Fork - Advanced Training
- **Autore**: Simone Garau ([@Simo93-rgb](https://github.com/Simo93-rgb))
- **Supervisori**:
  - Prof. Stefania Montani
  - Prof. Giorgio Leonardi
  - Prof. Manuel Striani

## ğŸš€ Quick Start
[Link a guida rapida]

## ğŸ“š Documentazione
- [Training Guide](docs/TRAIN_LLM_INTEGRATION.md)
- [K-Fold Cross Validation](docs/...)
- [Explainability](docs/...)
- [API Reference](docs/...)

## ğŸ› ï¸ Features
- K-Fold Cross Validation
- Focal Loss
- Integrated Gradients
- ...

## ğŸ“¦ Installation
[Istruzioni]

## ğŸ§ª Testing
[Comandi pytest]

## ğŸ“„ License
[License info]
```

**Output**: README.md professionale e completo

### Deliverable FASE 8:
âœ… Sistema completo testato (8.1, 8.2)  
â¸ï¸ Ensemble prediction validato (8.3)  
â¸ï¸ Documentazione audit (8.4.1)  
â¸ï¸ Documentazione pulita (8.4.2)  
â¸ï¸ Documentazione aggiornata (8.4.3)  
â¸ï¸ README.md professionale (8.4.4)

---

## ğŸ¯ Ordine di Esecuzione e Stato

### âœ… Completate:
1. âœ… **FASE 1** (Setup Base) - Configurazione, Focal Loss, Utilities
2. âœ… **FASE 2** (Best Model Tracking) - ModelCheckpoint
3. âœ… **FASE 3** (Early Stopping) - EarlyStopping avanzato
4. âœ… **FASE 4** (K-Fold CV) - KFoldTrainer + integrazione train_llm.py
5. âœ… **FASE 6** (Focal Loss CLI) - Completata durante FASE 4

### â¸ï¸ In Corso:
6. â¸ï¸ **FASE 8** (Testing & Validation) - 8.1 e 8.2 completati, 8.3 e 8.4 da fare

### ğŸ“‹ Da Fare:
7. â¸ï¸ **FASE 5** (Ensemble) - Averaging per predizione e XAI
8. â¸ï¸ **FASE 7** (Logging Bash) - Script `tee` per salvare output

### Dipendenze:
- **FASE 5** â†’ Necessaria per **FASE 8.3** (test ensemble)
- **FASE 8.4** â†’ PuÃ² iniziare subito (indipendente da FASE 5/7)
- **FASE 7** â†’ Indipendente, puÃ² essere fatta in parallelo

### ğŸ¯ Prossimi Step Consigliati:
1. **FASE 8.4.1-8.4.2**: Audit e pulizia documentazione (non richiede codice)
2. **FASE 5**: Implementazione ensemble (core functionality)
3. **FASE 7**: Logging bash (veloce, 1-2 modifiche)
4. **FASE 8.3**: Test ensemble (dopo FASE 5)
5. **FASE 8.4.3-8.4.4**: Aggiornamento doc + README finale

---

## ï¿½ Statistiche Progetto

### Codice Produzione:
```
src/training/
â”œâ”€â”€ config.py                [~350 righe] TrainingConfig
â”œâ”€â”€ focal_loss.py            [~360 righe] FocalLoss
â”œâ”€â”€ utils.py                 [~470 righe] Utilities
â”œâ”€â”€ checkpoint.py            [~330 righe] ModelCheckpoint
â”œâ”€â”€ early_stopping.py        [~350 righe] EarlyStopping
â”œâ”€â”€ kfold_trainer.py         [~420 righe] KFoldTrainer
â””â”€â”€ train_llm.py             [~760 righe] Main script (refactored)

src/models/
â””â”€â”€ neural_network.py        [~28 righe] LongFormer + GPT2 (refactored num_classes)

Total: ~3068 righe codice produzione
```

### Test Suite:
```
tests/
â”œâ”€â”€ test_training_phase1.py         [~450 righe] 23 test cases
â”œâ”€â”€ test_training_phase2.py         [~240 righe]  9 test cases
â”œâ”€â”€ test_training_phase3.py         [~220 righe] 11 test cases
â”œâ”€â”€ test_training_phase4.py         [~280 righe]  9 test cases
â”œâ”€â”€ test_training_phase4_3_1.py     [~252 righe] 11 test cases
â”œâ”€â”€ test_training_phase4_3_2.py     [~350 righe]  3 test cases
â”œâ”€â”€ test_training_phase4_3_3.py     [~200 righe]  9 test cases
â”œâ”€â”€ test_training_phase4_3_4.py     [~320 righe]  8 test cases
â””â”€â”€ test_num_classes_refactor.py    [~110 righe] 10 test cases

Total: ~2422 righe test, 93 test cases, tutti passing âœ…
```

### Documentazione:
```
docs/
â”œâ”€â”€ PIANO_LAVORI_FUNZIONALITÃ€_TRAINING.md  [~600 righe] Questo documento
â”œâ”€â”€ TRAIN_LLM_INTEGRATION.md               [~600 righe] Guida completa training
â”œâ”€â”€ REFACTORING_NUM_CLASSES.md             [~150 righe] Doc refactoring
â”œâ”€â”€ BUGFIX_MODEL_CONFIG.md
â”œâ”€â”€ EVALUATION_LOGGING.md
â”œâ”€â”€ EXPLAINABILITY_*.md
â””â”€â”€ ... (altri documenti da auditare in FASE 8.4.1)

Total: ~1350+ righe documentazione (stima, da auditare)
```

### ğŸ‰ Totale FASE 1-4 + Refactoring:
- **~3068 righe** codice produzione
- **~2422 righe** test suite (93 test cases)
- **~1350+ righe** documentazione
- **~6840+ righe TOTALI**
- **Test coverage**: 93 test passing âœ…
- **Branch**: `advanced-training`
- **Commit**: Multiple incrementali con storia completa

---

## ğŸ”§ FASE 4.3 - Integrazione train_llm.py (Dettagli Tecnici)

> **Nota**: Questa sezione contiene i dettagli tecnici completi dell'integrazione di tutte le features in `train_llm.py`. Per il riepilogo vedi [FASE 4](#-fase-4-k-fold-cross-validation-completata).

---

### âœ… 4.3.1 - Gestione CLI Arguments e TrainingConfig [COMPLETATO]
**Decisioni:**
- âœ… Argparse (resto progetto lo usa)
- âœ… CLI args: model_name, story_format, use_kfold, n_folds, use_focal_loss, focal_alpha, focal_gamma, patience, epochs
- âœ… Senza --use_kfold â†’ training semplice (backward compatibility)
- âœ… No config YAML, solo CLI

**Implementazione:**
- âœ… Aggiunto argparse con 10 parametri CLI
- âœ… Funzione `parse_args()` per parsing argomenti
- âœ… Funzione `create_training_config(args)` per creare TrainingConfig
- âœ… Sostituiti STORY_FORMAT, LEARNING_RATE, BATCH con config
- âœ… Mapping: epochsâ†’num_epochs, patienceâ†’early_stopping_patience, use_focal_lossâ†’loss_function
- âœ… Test: 11 test cases, tutti passing âœ…
- âœ… File: tests/test_training_phase4_3_1.py (~260 righe)

### âœ… 4.3.2 - Refactor pre_train() - Signature e Early Stopping [COMPLETATO]
**Decisioni:**
- âœ… Tutto su TrainingConfig (rimuovi num_epochs, min_loss, model_output_basename)
- âœ… Rimuovi start_epoch (sempre 0)
- âœ… Nome modello: config.get_model_filename(fold)
- âœ… Accelerator globale

**Implementazione:**
- âœ… Nuova signature: pre_train(model, optimizer, train_dataloader, val_dataloader, scheduler, criterion, accelerator, config, checkpoint, early_stopping, fold)
- âœ… Rimosso patience_counter custom, usato EarlyStopping class
- âœ… Compute metrics con balanced_accuracy come metrica principale
- âœ… ModelCheckpoint.update() per salvare best model
- âœ… EarlyStopping.update() + should_stop() per controllo
- âœ… restore_weights() per ripristinare best model al trigger
- âœ… Logging dettagliato per epoch (train/val loss e balanced_accuracy)
- âœ… Test: 3 test cases, tutti passing âœ…
- âœ… File: tests/test_training_phase4_3_2.py (~350 righe)

### âœ… 4.3.3 - Loss Function [COMPLETATO]
**Decisioni:**
- âœ… Class weights SOLO per CrossEntropyLoss (calcolo automatico)
- âœ… Focal Loss: gestisce giÃ  pesi con Î±/Î³ (no class weights)
- âœ… Metodo calcolo pesi: fisso 'balanced', no parametro CLI

**Implementazione:**
- âœ… Import `create_loss_from_config()` e `compute_class_weights()`
- âœ… Path Focal Loss: usa `create_loss_from_config(config)` con Î±/Î³ da config
- âœ… Path Cross Entropy: calcola class weights con metodo 'balanced', crea `nn.CrossEntropyLoss(weight=weights_tensor)`
- âœ… Logging configurazione loss function all'avvio
- âœ… Test: 9 test cases, tutti passing âœ…
- âœ… File: tests/test_training_phase4_3_3.py (~200 righe)

### âœ… 4.3.4 - Checkpoint e Model Saving [COMPLETATO]
**Decisioni:**
- âœ… Metrica: balanced_accuracy
- âœ… History gestito da checkpoint.save_history()
- âœ… Stampe centralizzate

**Implementazione:**
- âœ… Salvataggio automatic history alla fine del training con `checkpoint.save_history()`
- âœ… Logging info early stopping se triggerato (trigger epoch, best val loss, wait count)
- âœ… Summary finale con best epoch, best balanced_accuracy, path modello salvato
- âœ… History salvata in JSON: `checkpoint_history.json` (o `checkpoint_history_fold{k}.json` per K-Fold)
- âœ… Test: 8 test cases, tutti passing âœ…
- âœ… File: tests/test_training_phase4_3_4.py (~320 righe)

### âœ… 4.3.5 - K-Fold Wrapper [COMPLETATO]
**Decisioni:**
- âœ… Usa KFoldTrainer class (FASE 4.0) invece di logica custom
- âœ… Conditional routing: if config.use_kfold â†’ KFoldTrainer else â†’ simple training
- âœ… Model factory per creare modelli freschi per ogni fold
- âœ… Training function wrapper per chiamare pre_train() per ogni fold
- âœ… Dataset combinato da X_train + X_val per K-Fold

**Implementazione:**
- âœ… Import `KFoldTrainer` da `src.training.kfold_trainer`
- âœ… Conditional routing nella sezione main basato su `config.use_kfold`
- âœ… Model factory function: gestisce sia GPT2 che BERT-based models
- âœ… Train function wrapper: setup optimizer/scheduler/dataloader per fold, chiama pre_train()
- âœ… Aggregazione risultati: mean Â± std balanced_accuracy
- âœ… Backward compatibility: simple training preservato senza modifiche
- âœ… No test specifici (logica giÃ  coperta da 9 test FASE 4.0)

### âœ… 4.3.6 - Data Loading e Split Stratificato [COMPLETATO]
**Decisioni:**
- âœ… Test set giÃ  separato upstream (train.pickle / test.pickle) â†’ manteniamo
- âœ… Split train/val giÃ  stratificato con sklearn â†’ manteniamo (funziona bene)
- âœ… Label mapping generico: `CLS_0`, `CLS_1` invece di label specifiche
- âœ… Salva label2id/id2label in JSON per eval_model.py e extract_explainability.py

**Implementazione:**
- âœ… Import `analyze_class_distribution` da utils
- âœ… Creazione label mapping generico per export (`CLS_0`, `CLS_1`)
- âœ… Salvataggio JSON: `output/reports/label_mapping.json`
- âœ… Formato: `{"label2id": {"CLS_0": 0, ...}, "id2label": {"0": "CLS_0", ...}, "num_classes": 2}`
- âœ… Logging distribuzione classi per train/val/test set
- âœ… No test specifici (logica semplice: JSON save + print stats)

**Note:**
- Manteniamo `train_test_split` sklearn (giÃ  stratificato, no benefici a cambiare)
- `stratified_train_val_test_split()` da FASE 1 rimane inutilizzato â†’ vedi Refactoring Futuro

### âœ… 4.3.7 - Test di Integrazione [COMPLETATO]
**Decisioni:**
- âœ… Test con dati mock per velocitÃ 
- âœ… Test path corretti file salvati
- âœ… Test integrazione K-Fold routing
- âœ… No test GPU (troppo specifici)

**Implementazione:**
- âœ… Test implementati dall'utente
- âœ… Tutti i test passano
- âœ… Copertura completa funzionalitÃ 

### âœ… 4.3.8 - Documentazione [COMPLETATO]
**Decisioni:**
- âœ… File separato: docs/TRAIN_LLM_INTEGRATION.md
- âœ… Riferimento nel PIANO_LAVORI
- âœ… Esempi bash completi
- âœ… Best practices e troubleshooting

**Implementazione:**
- âœ… Creato `docs/TRAIN_LLM_INTEGRATION.md` (~600 righe)
- âœ… Sezioni:
  * Panoramica funzionalitÃ 
  * Utilizzo CLI e script bash
  * Parametri completi
  * Output e file generati
  * Workflow completo
  * Esempi pratici (4 scenari)
  * Interpretazione output console
  * Best practices
  * Troubleshooting
  * Riferimenti
- âœ… Esempi per ogni scenario: simple, K-Fold, Focal, K-Fold+Focal
- âœ… Guida scelta training mode e loss function
- âœ… Tuning hyperparameters e gestione risorse

**Riferimento completo:** [TRAIN_LLM_INTEGRATION.md](./TRAIN_LLM_INTEGRATION.md)

---

## ğŸ”„ REFACTORING FUTURO

### Codice Inutilizzato da Rimuovere/Consolidare

**1. `stratified_train_val_test_split()` in `src/training/utils.py`**
- **Stato**: Implementata in FASE 1.3, mai utilizzata
- **Motivo**: `train_llm.py` usa `train_test_split` di sklearn (giÃ  stratificato, test set giÃ  separato upstream)
- **Azione futura**: 
  - Opzione A: Rimuovere se confermato che non serve
  - Opzione B: Refactor pipeline XES per usarla upstream (split train/val/test prima del pickle)
- **PrioritÃ **: Bassa (non impatta funzionalitÃ )

**2. Possibili Duplicazioni da Verificare**
- **Da verificare**: Controllare se ci sono altre utility FASE 1 non utilizzate
- **Action**: Audit completo dopo FASE 8 (quando tutto Ã¨ integrato)

### Architettura Modelli - Refactoring da Multi-Classe a Generico

**3. Neural Network Classes - âœ… COMPLETATO (9 Ottobre 2025)**
- **File**: `src/models/neural_network.py`
- **Problema originale**: 
  - `LongFormerMultiClassificationHeads`: 8 classi hardcoded nel layer finale
  - `SimpleGPT2SequenceClassifier`: Riceve `num_classes` ma in `train_llm.py` era chiamato con 8 hardcoded
  - Progetto originale era multi-classe (8 DRG), ora deve supportare N-classi generico
- **Soluzione implementata**:
  - âœ… Aggiunto parametro `num_classes` a `LongFormerMultiClassificationHeads.__init__(num_classes=8)`
  - âœ… Default a 8 per backward compatibility con codice legacy
  - âœ… Aggiornato `train_llm.py` (linee 543-563) per usare `config.num_classes`
  - âœ… Aggiornato `model_factory` (linee 620-637) per usare `config.num_classes`
  - âœ… Ora completamente generico: supporta 2, 3, 8, N classi
- **Testing**: 
  - âœ… Test suite completa in `tests/test_num_classes_refactor.py` (10 test cases)
  - âœ… Verificato con classificazione binaria (2 classi) e multi-classe (3, 8, 10)
- **Riferimento**: Bug #4 durante test K-Fold, refactoring 9 Ottobre 2025
- **Documentazione**: [REFACTORING_NUM_CLASSES.md](./REFACTORING_NUM_CLASSES.md)

---

## ğŸ“ Summary e Prossimi Passi

### âœ… Cosa Abbiamo Completato (FASE 1-4, 6)
- **Infrastruttura completa**: Config, Focal Loss, Utilities, Checkpoint, Early Stopping
- **K-Fold Cross Validation**: Training robusto con stratificazione e metriche aggregate
- **CLI completo**: Parametri configurabili per tutte le features
- **Testing**: 93 test cases passing, test real-world completati
- **Refactoring**: Architettura modelli generica per N classi
- **Documentazione**: Guide complete per training e integrazione

### ğŸ¯ Prossimi Step Immediati
1. **FASE 8.4.1**: Audit documentazione (`docs/`) - Capire cosa c'Ã¨ e cosa serve
2. **FASE 5**: Implementare `EnsembleModel` per averaging predizioni e pesi (XAI compatibility)
3. **FASE 7**: Aggiungere `tee` negli script bash per logging su file
4. **FASE 8.3**: Test ensemble prediction (dopo FASE 5)
5. **FASE 8.4.2-8.4.4**: Pulizia, aggiornamento doc, README professionale

### ğŸ“‹ Roadmap Finale
```
[âœ… COMPLETATE] FASE 1, 2, 3, 4, 6
    â†“
[â¸ï¸ DA FARE] FASE 8.4.1 (Audit docs) â†’ PuÃ² iniziare subito
    â†“
[â¸ï¸ DA FARE] FASE 5 (Ensemble) â†’ Core functionality
    â†“
[â¸ï¸ DA FARE] FASE 7 (Logging bash) â†’ Quick win
    â†“
[â¸ï¸ DA FARE] FASE 8.3 (Test ensemble) â†’ Dopo FASE 5
    â†“
[â¸ï¸ DA FARE] FASE 8.4.2-8.4.4 (Doc finale + README) â†’ Polish
    â†“
[âœ… MERGE] advanced-training â†’ master
```

### ğŸ‰ Progetto LEGOLAS Fork - Advanced Training
**Repository**: https://github.com/Simo93-rgb/LEGOLAS  
**Branch**: `advanced-training`  
**Autore Fork**: Simone Garau ([@Simo93-rgb](https://github.com/Simo93-rgb))  
**Supervisori**: Prof. Stefania Montani, Prof. Giorgio Leonardi, Prof. Manuel Striani  
**Progetto Originale**: LEGOLAS - Articolo scientifico [citazione da aggiungere in README]

---

**Fine Piano Lavori**  
*Ultimo aggiornamento: 10 Ottobre 2025*
