# LEGOLAS - Diagrammi di Flusso

Questa cartella contiene i diagrammi di flusso dettagliati per i componenti principali del sistema LEGOLAS.

---

## ğŸ“Š Diagrammi Disponibili

### 1. [Training LLM](TRAIN_LLM_FLOWCHART.md)
**File**: `train_llm.py`  
**Funzione**: Training di modelli LLM su storie cliniche XES

**ModalitÃ  supportate**:
- âœ… Training Semplice (train/val split)
- âœ… K-Fold Cross Validation
- âœ… Focal Loss per classi sbilanciate
- âœ… Cross Entropy con class weights automatici

**Diagrammi inclusi**:
- Flusso principale end-to-end
- Parse arguments e configurazione
- K-Fold Cross Validation mode
- Simple training mode
- Training loop dettagliato (pre_train)
- Decision tree per scegliere modalitÃ 
- Integrazione con altri componenti

**Quando consultare**:
- Prima di lanciare un training
- Per capire differenze tra modalitÃ  semplice e K-Fold
- Per debuggare problemi di training
- Per scegliere loss function appropriata

---

### 2. [Extract Explainability](EXTRACT_EXPLAINABILITY_FLOWCHART.md)
**File**: `extract_explainability.py`  
**Funzione**: Estrazione attribution scores con Integrated Gradients

**ModalitÃ  supportate**:
- âœ… Single Model Explainability
- âœ… Ensemble Model Explainability (K-Fold)
- âœ… Adaptive IG steps strategy (1500â†’5500)
- âœ… Clinical actions aggregation

**Diagrammi inclusi**:
- Flusso principale end-to-end
- Load data (test/train/all)
- Load model (single/ensemble)
- Get predictions
- Ensemble IG extraction
- Single model IG extraction
- Visualizations pipeline
- Adaptive strategy helper

**Quando consultare**:
- Prima di estrarre explainability
- Per capire strategia adattiva IG
- Per debuggare convergenza IG
- Per comprendere differenze single/ensemble

---

## ğŸ—ºï¸ Relazioni tra Componenti

```mermaid
flowchart LR
    XES[XES Pipeline<br/>run_xes_pipeline.sh] -->|genera| Stories[Stories<br/>output/stories/]
    
    Stories --> Train[Training<br/>train_llm.py]
    
    Train -->|produce| Models[Models<br/>output/models/]
    Train -->|produce| Mapping[Label Mapping<br/>output/reports/]
    
    Models --> Eval[Evaluation<br/>eval_model.py]
    Mapping --> Eval
    
    Models --> XAI[Explainability<br/>extract_explainability.py]
    Mapping --> XAI
    Stories --> XAI
    
    XAI -->|genera| Viz[Visualizations<br/>output/explainability/]
    
    style Train fill:#DDA0DD
    style XAI fill:#FFB6C1
    style Eval fill:#87CEEB
```

---

## ğŸ“ Struttura File Output

### Training (train_llm.py)
```
output/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ best_model_{format}_{model}.pth              # Simple training
â”‚   â”œâ”€â”€ best_model_{format}_{model}_fold*.pth        # K-Fold models
â”‚   â””â”€â”€ training_history_{format}_{model}*.json     # Training metrics
â””â”€â”€ reports/
    â”œâ”€â”€ label_mapping.json                            # Label mapping (usato da eval/xai)
    â”œâ”€â”€ fold_*_{format}_{model}_metrics.json         # K-Fold metrics per fold
    â””â”€â”€ kfold_aggregated_{format}_{model}_results.json  # K-Fold aggregated
```

### Explainability (extract_explainability.py)
```
output/
â””â”€â”€ explainability/
    â”œâ”€â”€ ig_results_{format}_{model}_{mode}_{timestamp}.pkl         # Raw IG results
    â”œâ”€â”€ actions_{format}_{model}_{mode}_{timestamp}.pkl            # Clinical actions
    â”œâ”€â”€ heatmap_words_{format}_{model}_{mode}_{timestamp}.png     # Word heatmap
    â”œâ”€â”€ histogram_words_{format}_{model}_{mode}_{timestamp}.png   # Word histogram
    â”œâ”€â”€ heatmap_actions_{format}_{model}_{mode}_{timestamp}.png   # Actions heatmap â­
    â””â”€â”€ histogram_actions_{format}_{model}_{mode}_{timestamp}.png # Actions histogram â­
```

â­ = File principali per interpretabilitÃ  clinica

---

## ğŸ”§ Script Helper

### Esecuzione Interattiva Training
```bash
# Script interattivo con menu
./scripts/run_train_eval.sh

# Il menu guida attraverso:
# 1. Scelta azione (train/eval/both)
# 2. Scelta formato storie
# 3. Scelta modello
# 4. ModalitÃ  training (semplice/K-Fold) 
# 5. Loss function (CE/Focal)
# 6. Hyperparameters
# 7. Evaluation mode (single/ensemble)
```

### Esecuzione Diretta Training
```bash
# Training semplice con CE Loss
uv run python src/training/train_llm.py \
  --model_name bert-base-uncased \
  --story_format narrativo \
  --epochs 10 \
  --batch_size 16

# K-Fold con Focal Loss
uv run python src/training/train_llm.py \
  --model_name clinical-bert \
  --story_format narrativo \
  --use_kfold \
  --n_folds 5 \
  --use_focal_loss \
  --focal_alpha 0.25 0.75
```

### Esecuzione Diretta Explainability
```bash
# Single model con adaptive IG
uv run python src/explainability/extract_explainability.py \
  --model bert-base-uncased \
  --format narrativo \
  --adaptive_steps

# Ensemble con fixed IG
uv run python src/explainability/extract_explainability.py \
  --model clinical-bert \
  --format narrativo \
  --use_ensemble \
  --n_steps 5500
```

---

## ğŸ“– Documentazione Correlata

- **Training Guide**: `docs/TRAIN_LLM_INTEGRATION.md`
- **Explainability Guide**: `docs/EXPLAINABILITY_GUIDE.md`
- **Model Configuration**: `docs/MODEL_CONFIG_GUIDE.md`
- **Path Management**: `src/config/paths.py`
- **Adaptive IG Refactoring**: `docs/ADAPTIVE_IG_REFACTORING.md`

---

## ğŸ†• Changelog

### 2025-10-22
- âœ… Aggiunto supporto modalitÃ  training opzionale (semplice/K-Fold) in `run_train_eval.sh`
- âœ… Creato `TRAIN_LLM_FLOWCHART.md` con diagrammi completi
- âœ… Spostato `EXTRACT_EXPLAINABILITY_FLOWCHART.md` in `docs/flowcharts/`
- âœ… Aggiornato focus visualizzazioni su Classe 1 (target principale)
- âœ… Uniformati valori adaptive IG (1500â†’5500)
- âœ… Creato questo INDEX per navigazione rapida

---